{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2b28c9",
   "metadata": {},
   "source": [
    "### [`sklearn.svm`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm \"sklearn.svm\").SVC\n",
    "* _class_ sklearn.svm.SVC(_*_,  _C=1.0_,  _kernel='rbf'_,  _degree=3_,  _gamma='scale'_,  _coef0=0.0_,  _shrinking=True_,  _probability=False_,  _tol=0.001_,  _cache_size=200_,  _class_weight=None_,  _verbose=False_,  _max_iter=-1_,  _decision_function_shape='ovr'_,  _break_ties=False_,  _random_state=None_)[[source]](https://github.com/scikit-learn/scikit-learn/blob/7db5b6a98/sklearn/svm/_classes.py#L554)[](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC \"Permalink to this definition\")\n",
    "\n",
    "**Parameter** : **C** : float, default=1.0\n",
    "\n",
    "Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.\n",
    "\n",
    "**kernel** : {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} or callable, default=’rbf’\n",
    "\n",
    "Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape  `(n_samples,  n_samples)`.\n",
    "\n",
    "**degree** : int, default=3\n",
    "\n",
    "Degree of the polynomial kernel function (‘poly’). Must be non-negative. Ignored by all other kernels.\n",
    "\n",
    "**gamma** : {‘scale’, ‘auto’} or float, default=’scale’\n",
    "\n",
    "Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.\n",
    "\n",
    "-   if  `gamma='scale'`  (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
    "    \n",
    "-   if ‘auto’, uses 1 / n_features\n",
    "    \n",
    "-   if float, must be non-negative.\n",
    "    \n",
    "\n",
    "Changed in version 0.22: The default value of  `gamma`  changed from ‘auto’ to ‘scale’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ec65153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "label = iris.target\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'gamma' : [0.1, 0.05, 0.001],\n",
    "    'C' : [1, 10, 100]\n",
    "}\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "g_tree = GridSearchCV(dtc, param_grid=params, cv=5, refit=True)\n",
    "g_tree.fit(X_train, y_train)\n",
    "\n",
    "print('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3b79c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터 :  {'C': 1, 'gamma': 0.1}\n",
      "최적의 점수 :  0.96\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m최적의 파라미터 : \u001b[39m\u001b[38;5;124m'\u001b[39m, sv_tree\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m최적의 점수 : \u001b[39m\u001b[38;5;124m'\u001b[39m, sv_tree\u001b[38;5;241m.\u001b[39mbest_score_)\n\u001b[1;32m---> 13\u001b[0m preditions \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test, preditions))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:807\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;124;03m\"\"\"Perform classification on samples in X.\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \n\u001b[0;32m    793\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 or -1 is returned.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;124;03m        Class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbreak_ties \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function_shape \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    809\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    810\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbreak_ties must be False when decision_function_shape is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    811\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1386\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1387\u001b[0m     ]\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'gamma' : [0.1, 0.05, 0.001],\n",
    "    'C' : [1, 10, 100]\n",
    "}\n",
    "\n",
    "clf = SVC()\n",
    "sv_tree = GridSearchCV(clf, param_grid=params, cv=3, refit=True)\n",
    "sv_tree.fit(X_train, y_train)\n",
    "\n",
    "print('최적의 파라미터 : ', sv_tree.best_params_)\n",
    "print('최적의 점수 : ', sv_tree.best_score_)\n",
    "\n",
    "preditions = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, preditions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d449dd2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 1 2 0 0 1 0 0 0 0 1 2 2 0 0 1 0 1 0 0 2 0 0 0 1 1 2 0 2 1 0 0 0 0 0\n",
      " 0 2 2 1 1 0 2 0 1 2 0 0 1 0 1 0 2 1 0 2 2 1 0 0 0 1 0 2 2 1 2 2 2 2 2 1 2\n",
      " 0]\n",
      "0.96\n",
      "0.9466666666666667\n",
      "0.26666666666666666\n",
      "0.9466666666666667\n",
      "0.9733333333333334\n",
      "0.9333333333333333\n",
      "0.9733333333333334\n",
      "0.9466666666666667\n",
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma=0.1, C=1)\n",
    "clf_1 = SVC(gamma=0.05, C=1)\n",
    "clf_2 = SVC(gamma=0.001, C=1)\n",
    "\n",
    "clf_3 = SVC(gamma=0.1, C=10)\n",
    "clf_4 = SVC(gamma=0.05, C=10)\n",
    "clf_5 = SVC(gamma=0.001, C=10)\n",
    "\n",
    "clf_6 = SVC(gamma=0.1, C=100)\n",
    "clf_7 = SVC(gamma=0.05, C=100)\n",
    "clf_8 = SVC(gamma=0.001, C=100)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf_1.fit(X_train, y_train)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "clf_3.fit(X_train, y_train)\n",
    "clf_4.fit(X_train, y_train)\n",
    "clf_5.fit(X_train, y_train)\n",
    "\n",
    "clf_6.fit(X_train, y_train)\n",
    "clf_7.fit(X_train, y_train)\n",
    "clf_8.fit(X_train, y_train)\n",
    "\n",
    "preditions = clf.predict(X_test)\n",
    "preditions_1 = clf_1.predict(X_test)\n",
    "preditions_2 = clf_2.predict(X_test)\n",
    "\n",
    "preditions_3 = clf_3.predict(X_test)\n",
    "preditions_4 = clf_4.predict(X_test)\n",
    "preditions_5 = clf_5.predict(X_test)\n",
    "\n",
    "preditions_6 = clf_6.predict(X_test)\n",
    "preditions_7 = clf_7.predict(X_test)\n",
    "preditions_8 = clf_8.predict(X_test)\n",
    "\n",
    "print(y_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, preditions))\n",
    "print(accuracy_score(y_test, preditions_1))\n",
    "print(accuracy_score(y_test, preditions_2))\n",
    "\n",
    "print(accuracy_score(y_test, preditions_3))\n",
    "print(accuracy_score(y_test, preditions_4))\n",
    "print(accuracy_score(y_test, preditions_5))\n",
    "\n",
    "print(accuracy_score(y_test, preditions_6))\n",
    "print(accuracy_score(y_test, preditions_7))\n",
    "print(accuracy_score(y_test, preditions_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20edb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
